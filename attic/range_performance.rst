If combined with a suitable term-based query (such as an `OP_AND`
query over one or more terms), this performance impact will be less
because the range operation will only have to run over the potential
matches, which are reduced from the entire database by the term-based
query.

If, as well as using document values, you also convert groups of those
values into terms, you can provide those term-based queries even when
your users are only interested in a pure range search. For instance,
consider the population information. If you divide the range of
populations into a number of subranges, you can allocate a term to
describe each. We'll use a prefix of `XP` (for "population") here.

+------------------+------+
| Population range | Term |
+==================+======+
| 0 - 10 million   | XP0  |
+------------------+------+
| 10 - 20 million  | XP1  |
+------------------+------+
| 20 - 30 million  | XP2  |
+------------------+------+
| 30 - 40 million  | XP3  |
+------------------+------+

Then you can use a custom :xapian-class:`ValueRangeProcessor` to both generate
the relevant information for QueryParser to construct an
:xapian-just-constant:`OP_VALUE_RANGE` query and to record which subranges we're
interested in. For instance, if the user asks for '..15000000', your processor
can remember that and later spit out an additional
:xapian-just-constant:`OP_AND` query with terms `XP0` and `XP1`, that can be
combined with the query generated by the QueryParser using
:xapian-just-constant:`OP_FILTER`.

.. todo:: actually, you can't safely combine the query with an external filter,
	  because other bits of the query might be higher level.  For example,
	  a query of '1790..1799 OR york' couldn't have the filter applied to
	  the generated query because it shouldn't be applied to the "york"
	  part.

.. todo:: possibly implementing this example would help make it more clear.
